[GPT2.all.default.all.generate]

input = '''
TensorRT is a Deep Learning compiler used for deep learning.
'''

label = '''
TensorRT is a Deep Learning compiler used for deep learning.\n\nThe main goal of the project is to create a tool that can be used to train neural networks.\n\nThe main goal of the project is to create a tool that can
'''

[GPT2.all.gpt2-medium.all.generate]

label = '''
TensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning. TensorRT is a deep learning library for Python.\n\nTensorRT is a deep learning library for
'''

[GPT2.all.gpt2-large.all.generate]

label = '''
TensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning. TensorFlow is a high-performance, open-source, cross-platform, high-performance, machine
'''

[GPT2.all.gpt2-xl.all.generate]

label = '''
TensorRT is a Deep Learning compiler used for deep learning.\n\nThe library is written in C++ and uses Boost.Python.\n\nThe library is available on GitHub.\n\nInstallation\n\nThe library is available on GitHub.\n
'''

[GPT2.all."EleutherAI/gpt-j-6B".all.generate]

label = '''
TensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a deep learning compiler that enables you to run deep learning models on NVIDIA GPUs.\n\nTensorRT is a deep learning compiler that enables you to run
'''

[GPT2.all."EleutherAI/gpt-neo-125m".all.generate]

label = '''
TensorRT is a Deep Learning compiler used for deep learning.\n\nThe following code is a sample of the code used in the previous section.\n\n#include <cmath>\n#include <cstdlib>\n#include <cstring>\n#include <cstdio>\n#include <cstring>\n#include <cstdio>\n#include <cstdlib>\n#include <cstdlib>\n#include <cstdlib>
'''

[GPT2.all."EleutherAI/gpt-neo-1.3B".all.generate]

label = '''
TensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a deep learning compiler used for deep learning.\n\nTensorRT is a deep learning compiler used for deep learning.\n\nTensorRT is a
'''

[GPT2.all."EleutherAI/gpt-neo-2.7B".all.generate]

label = '''
TensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\n−\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\n+\n
'''

[GPT2.all."EleutherAI/gpt-neox-20b".all.generate]

label = '''
TensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a deep learning compiler used for deep learning.\n\nTensorRT is a deep learning compiler used for deep learning.\n\nTensorRT is a deep learning compiler used for deep learning.\n\nTensorRT is a deep learning compiler used for deep learning.\n\nTensorRT is a deep learning compiler used for deep learning.\n\nTensorRT is a deep learning compiler used for deep learning.\n\nTensorRT
'''

[GPT2.all."facebook/opt-125m".all.generate]

label = '''
TensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used
'''

[GPT2.all."facebook/opt-350m".all.generate]

label = '''
TensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used
'''

[GPT2.all."facebook/opt-1.3b".all.generate]

label = '''
TensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used
'''

[GPT2.all."facebook/opt-2.7b".all.generate]

label = '''
TensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a compiler for deep learning. It is a tool for building neural networks and is used to train neural networks.\n\nTensorRT is a compiler for deep learning. It is a tool for building neural networks and is used to train neural networks.\n\nTensorRT is a compiler for deep learning. It is a tool for building neural networks and is used to train neural networks.\n\n
'''

[GPT2.all."facebook/opt-6.7b".all.generate]

label = '''
TensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used
'''

[GPT2.all."facebook/opt-13b".all.generate]

label = '''
TensorRT is a Deep Learning compiler used for deep learning.\n\nTensorRT is a Deep Learning compiler used for deep learning.\n\n−\n\n== Installation ==\n\n+\n\n== Installation ==\n\n−\n\nTensorRT is available in the [http://www.nvidia.com/downloads/download.aspx?product=nvidia-tensor-rt-compiler-for-cuda-v100-and-v200-
'''

[GPT2.all.default.fp16.generate]

label = '''
TensorRT is a Deep Learning compiler used for deep learning.\n\nThe main goal of the project is to provide a way to build a deep learning framework that can be used to build a deep learning framework for a wide range of applications.\n
'''

[GPT2.all.default.all.generate_b]

input = '''
GPT-2 is a transformer based model pretrained on a large corpus.
'''

label = '''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nThe model is based on the following assumptions:\n\nThe model is based on the following assumptions:\n\nThe model is based on the following assumptions:\n
'''

[GPT2.all.gpt2-medium.all.generate_b]

label = '''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nThe model is trained on a large corpus of data, and the model is trained on a large number of training examples. The model is trained on a large number
'''

[GPT2.all.gpt2-large.all.generate_b]

label = '''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nThe model is trained on the following data:\n\nThe corpus consists of the following text files:\n\nThe corpus is split into two parts:\n\n
'''

[GPT2.all.gpt2-xl.all.generate_b]

label = '''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nThe model is trained on the MNIST dataset, which contains over 100,000 handwritten digits. The training data is split into two parts: the training set and
'''

[GPT2.all."EleutherAI/gpt-j-6B".all.generate_b]

label = '''
GPT-2 is a transformer based model pretrained on a large corpus.\n\n-   **GPT-2-PT**: The same as GPT-2 but with the pretrained model.\n\n-   **
'''

[GPT2.all."EleutherAI/gpt-neo-125m".all.generate_b]

label = '''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nThe model is trained on the corpus of the same size as the corpus of the same size as the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of
'''

[GPT2.all."EleutherAI/gpt-neo-1.3B".all.generate_b]

label = '''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nThe model is trained on the GPT-2 dataset [@radford2019language] and is pretrained on the English Wikipedia. The model is trained on
'''

[GPT2.all."EleutherAI/gpt-neo-2.7B".all.generate_b]

label = '''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nThe model is trained on the following corpora:\n\n-   **GPT-2**: The GPT-2 model is trained on the
'''

[GPT2.all."EleutherAI/gpt-neox-20b".all.generate_b]

label = '''
GPT-2 is a transformer based model pretrained on a large corpus.\n\n-   **BERT** [@devlin2018bert] is a deep bidirectional transformer model pretrained on a large corpus.\n\n-   **RoBERTa** [@liu2019roberta] is a deep bidirectional transformer model pretrained on a large corpus.\n\n-   **XLNet** [@yang2019xlnet] is a deep bidirectional transformer model pretrained on
'''

[GPT2.all."facebook/opt-125m".all.generate_b]

label = '''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nThe GPT-2 is a transformer based model pretrained on a large corpus.\n\nThe GPT-2 is a transformer based model pretrained on a large corpus.\n\nThe GPT-2 is a transformer based model pretrained on a large corpus.\n\nThe GPT-2 is a transformer based model pretrained on a large corpus.\n\nThe GPT-2
'''

[GPT2.all."facebook/opt-350m".all.generate_b]

label = '''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nGPT-2 is a transformer based model pretrained on a large corpus.\n\nGPT-2 is a transformer based model pretrained on a large corpus.\n\nGPT-2 is a transformer based model pretrained on a large corpus.\n\nGPT-2 is a transformer based model pretrained on a large corpus.\n\nGPT-2 is a transformer based model
'''

[GPT2.all."facebook/opt-1.3b".all.generate_b]

label = '''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nGPT-2 is a transformer based model pretrained on a large corpus.\n\nGPT-2 is a transformer based model pretrained on a large corpus.\n\nGPT-2 is a transformer based model pretrained on a large corpus.\n\nGPT-2 is a transformer based model pretrained on a large corpus.\n\nGPT-2 is a transformer based model
'''

[GPT2.all."facebook/opt-2.7b".all.generate_b]

label = '''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nGPT-2 is a transformer based model pretrained on a large corpus.\n\nGPT-2 is a transformer based model pretrained on a large corpus.\n\nGPT-2 is a transformer based model pretrained on a large corpus.\n\nGPT-2 is a transformer based model pretrained on a large corpus.\n\nGPT-2 is a transformer based model
'''

[GPT2.all."facebook/opt-6.7b".all.generate_b]

label = '''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nGPT-2 is a transformer based model pretrained on a large corpus.\n\nGPT-2 is a transformer based model pretrained on a large corpus.\n\nGPT-2 is a transformer based model pretrained on a large corpus.\n\nGPT-2 is a transformer based model pretrained on a large corpus.\n\nGPT-2 is a transformer based model
'''

[GPT2.all."facebook/opt-13b".all.generate_b]

label = '''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nIt is a transformer based model that is pretrained on a large corpus.\n\nIt is a transformer based model that is pretrained on a large corpus.\n\nIt is a transformer based model that is pretrained on a large corpus.\n\nIt is a transformer based model that is pretrained on a large corpus.\n\nIt is a transformer based model that is pretrained on a large
'''

[GPT2.all.default.all.generate_c]

input = '''
If I fall asleep then I am going to wake up in 8 hours.
'''

label = '''
If I fall asleep then I am going to wake up in 8 hours.\n\nI am not going to sleep for 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours
'''

[GPT2.all.gpt2-medium.all.generate_c]

label = '''
If I fall asleep then I am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours
'''

[GPT2.all.gpt2-large.all.generate_c]

label = '''
If I fall asleep then I am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours
'''

[GPT2.all.gpt2-xl.all.generate_c]

label = '''
If I fall asleep then I am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours
'''

[GPT2.all."EleutherAI/gpt-j-6B".all.generate_c]

label = '''
If I fall asleep then I am going to wake up in 8 hours.\n\nI am going to be in the same place.\n\nI am going to be in the same place.\n\nI am going to be in the same place
'''

[GPT2.all."EleutherAI/gpt-neo-125m".all.generate_c]

label = '''
If I fall asleep then I am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n
'''

[GPT2.all."EleutherAI/gpt-neo-1.3B".all.generate_c]

label = '''
If I fall asleep then I am going to wake up in 8 hours.\n\nI am not going to fall asleep.\n\nI am going to wake up in 8 hours.\n\nI am not going to fall asleep.\n\nI
'''

[GPT2.all."EleutherAI/gpt-neo-2.7B".all.generate_c]

label = '''
If I fall asleep then I am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours
'''

[GPT2.all."EleutherAI/gpt-neox-20b".all.generate_c]

label = '''
If I fall asleep then I am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n
'''

[GPT2.all."facebook/opt-125m".all.generate_c]

label = '''
If I fall asleep then I am going to wake up in 8 hours.\nI'm not sure if I'm dreaming or not.\nI'm not sure if I'm dreaming or not.\nI'm not sure if I'm dreaming or not.\nI'm not sure if I'm dreaming or not.\nI'm not sure if I'm dreaming or not.\nI'm not sure if I'm dreaming or not.\nI'm not sure if I'm dreaming or not.
'''

[GPT2.all."facebook/opt-350m".all.generate_c]

label = '''
If I fall asleep then I am going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up
'''

[GPT2.all."facebook/opt-1.3b".all.generate_c]

label = '''
If I fall asleep then I am going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up
'''

[GPT2.all."facebook/opt-2.7b".all.generate_c]

label = '''
If I fall asleep then I am going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up
'''

[GPT2.all."facebook/opt-6.7b".all.generate_c]

label = '''
If I fall asleep then I am going to wake up in 8 hours.\nI'm not sure if I should be happy or sad about this.
'''

[GPT2.all."facebook/opt-13b".all.generate_c]

label = '''
If I fall asleep then I am going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up in 8 hours.\nI'm going to wake up
'''

[GPT2.all.default.all.generate_d]

input = [
'''
GPT-2 is a transformer based model pretrained on a large corpus.
''',
'''
If I fall asleep then I am going to wake up in 8 hours.
''']

label = [
'''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nThe model is based on the following assumptions:\n\nThe model is based on the following assumptions:\n\nThe model is based on the following assumptions:\n
''',
'''
If I fall asleep then I am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8
''']

[GPT2.all.gpt2-medium.all.generate_d]

label = [
'''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nThe model is trained on a large corpus of data, and the model is trained on a large number of training examples. The model is trained on a large number
''',
'''
If I fall asleep then I am going to wake up in 8 hours.\n\nIf I fall asleep then I am going to wake up in 8 hours.\n\nIf I fall asleep then I am going to wake up in 8 hours.
''']

[GPT2.all.gpt2-large.all.generate_d]

label = [
'''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nThe model is trained on the following data:\n\nThe corpus consists of the following text files:\n\nThe corpus is split into two parts:\n\n
''',
'''
If I fall asleep then I am going to wake up in 8 hours.\n\nIf I fall asleep then I am going to wake up in 8 hours.\n\nIf I fall asleep then I am going to wake up in 8 hours.
''']

[GPT2.all.gpt2-xl.all.generate_d]

label = [
'''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nThe model is trained on the MNIST dataset, which contains over 100,000 handwritten digits. The training data is split into two parts: the training set and
''',
'''
If I fall asleep then I am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8
''']

[GPT2.all."EleutherAI/gpt-j-6B".all.generate_d]

label = [
'''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nThe model is based on the following assumptions:\n\nThe model is based on the following assumptions:\n\nThe model is based on the following assumptions:\n
''',
'''
If I fall asleep then I am going to wake up in 8 hours.\n\nIf I fall asleep then I am going to wake up in 8 hours.\n\nIf I fall asleep then I am going to wake up in 8 hours.
''']

[GPT2.all."EleutherAI/gpt-neo-125m".all.generate_d]

label = [
'''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nThe model is trained on the corpus of the same size as the corpus of the same size as the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of the corpus of
''',
'''
If I fall asleep then I am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.
''']

[GPT2.all."EleutherAI/gpt-neo-1.3B".all.generate_d]

label = [
'''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nThe model is trained on the GPT-2 dataset [@radford2019language] and is pretrained on the English Wikipedia. The model is trained on
''',
'''
If I fall asleep then I am going to wake up in 8 hours.\n\nI am not a morning person. I am a night person. I am a night person. I am a night person. I am a night person. I
''']

[GPT2.all."EleutherAI/gpt-neo-2.7B".all.generate_d]

label = [
'''
GPT-2 is a transformer based model pretrained on a large corpus.\n\nThe model is trained on the following corpora:\n\n-   **GPT-2**: The GPT-2 model is trained on the
''',
'''
If I fall asleep then I am going to wake up in 8 hours.\n\nIf I fall asleep then I am going to wake up in 8 hours.\n\nIf I fall asleep then I am going to wake up in 8 hours.
''']

[GPT2.all."EleutherAI/gpt-neox-20b".all.generate_d]

label = [
'''
GPT-2 is a transformer based model pretrained on a large corpus.\n\n-   **BERT** [@devlin2018bert] is a deep bidirectional transformer model pretrained on a large corpus.\n\n-   **RoBERTa** [@liu2019roberta] is a deep bidirectional transformer model pretrained on a large corpus.\n\n-   **XLNet** [@yang2019xlnet] is a deep bidirectional transformer model pretrained on
''',
'''
If I fall asleep then I am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n\nI am going to wake up in 8 hours.\n
''']

